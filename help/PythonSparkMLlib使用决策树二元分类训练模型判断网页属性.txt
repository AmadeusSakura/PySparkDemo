HADOOP_CONF_DIR=/usr/local/hadoop/hadoop-2.6.4/etc/hadoop pyspark --master yarn --deploy-mode client

import  os, sys
import numpy as np
from time import time
from pyspark import SparkContext, SparkConf
from pyspark.mllib.regression import LabeledPoint
from pyspark.mllib.tree import DecisionTree
from pyspark.mllib.evaluation import BinaryClassificationMetrics
import pandas as pd
import matplotlib.pyplot as plt

global Path

if sc.master[0:5] == 'local':
    Path='file:/root/pythonwork/PythonProject/'
else:
    Path='hdfs://master:9000/user/root/'

rawDataWithHeader = sc.textFile(Path + 'data/stumbleupon/train.tsv')
header = rawDataWithHeader.first()
rawData = rawDataWithHeader.filter(lambda x: x != header)
rData = rawData.map(lambda x: x.replace('\"', ''))
lines = rData.map(lambda x: x.split('\t'))
print('========== [PrepareData] >>>> 共计：' + str(lines.count()) + ' 项')

def extract_label(field):
    label = (field[-1])
    return float(label)

def extract_features(field, categoriesMap, featureEnd):
    categoryIdx = categoriesMap[field[3]]
    categoryFeatures = np.zeros(len(categoriesMap))
    categoryFeatures[categoryIdx] = 1
    numericalFeatures = [convert_float(field) for field in field[4:featureEnd]]
    return np.concatenate((categoryFeatures, numericalFeatures))

def convert_float(x):
    return (0 if x == '?' else float(x))

categoriesMap = lines.map(lambda fields: fields[3]).distinct().zipWithIndex().collectAsMap()

len(categoriesMap)
type(categoriesMap)

labelpointRDD = lines.map(lambda r: LabeledPoint(extract_label(r), extract_features(r, categoriesMap, len(r) - 1)))

(trainData, validationData, testData) = labelpointRDD.randomSplit([8, 1, 1])

print('========== [PrepareData] >>>> 将数据以随机方式差分为三个部分：trainData: ' + str(trainData.count()) + ' 项, validationData: ' + str(validationData.count()) + ' 项, testData: ' + str(testData.count()) + ' 项')

trainData.persist()
validationData.persist()
testData.persist()

model = DecisionTree.trainClassifier(trainData, numClasses=2, categoricalFeaturesInfo={}, impurity='entropy', maxDepth=5, maxBins=5)

def PredictData(sc, model, categoriesMap):
    print('======================= 预测数据 =======================')
    print('========== [PredictData] >>>> 开始导入 test.tsv 数据....')
    rawDataWithHeader = sc.textFile(Path + u'data/stumbleupon/test.tsv')
    header = rawDataWithHeader.first()
    rawData = rawDataWithHeader.filter(lambda x: x != header)
    rData = rawData.map(lambda x: x.replace('\"', ''))
    lines = rData.map(lambda x: x.split('\t'))
    print('========== [PredictData] >>>> 共计：' + str(lines.count()) + ' 项')
    dataRDD = lines.map(lambda r: (r[0], extract_features(r, categoriesMap, len(r))))
    DescDict = {
        0: '暂时性网页(ephemeral)',
        1: '长青网页(evergreen)'
    }
    for data in dataRDD.take(10):
        predictResult = model.predict(data[1])
        print('========== [PredictData] >>>> 网址：' + str(data[0]) + '\n' + '\t\t==>> 预测：' + str(predictResult) + ', 说明：' + DescDict[predictResult] + '\n')


PredictData(sc, model, categoriesMap)

score = model.predict(validationData.map(lambda p: p.features))
scoreAndLabels = score.zip(validationData.map(lambda p: p.label))
scoreAndLabels.take(5)
metrics = BinaryClassificationMetrics(scoreAndLabels)
AUC = metrics.areaUnderROC


def evaluateModel(model, validationData):
    score = model.predict(validationData.map(lambda p: p.features))
    scoreAndLabels = score.zip(validationData.map(lambda p: p.label))
    metrics = BinaryClassificationMetrics(scoreAndLabels)
    AUC = metrics.areaUnderROC
    return (AUC)


def trainEvaluateModel(trainData, validationData, impurityParm, maxDepthParm, maxBinsParm):
    print('======================= 训练评估模型 =======================')
    startTime = time()
    model = DecisionTree.trainClassifier(trainData, numClasses=2, categoricalFeaturesInfo={}, impurity=impurityParm, maxDepth=maxDepthParm, maxBins=maxBinsParm)
    AUC = evaluateModel(model, validationData)
    duration = time() - startTime
    print('========== [trainEvaluateModel] >>>> 训练评估模型：使用参数：impurity=' + str(impurityParm) + ', maxDepth=' + str(maxDepthParm) + ', maxBins=' + str(maxBinsParm) + '\n' + '\t\t==>> 所需时间=' + str(duration) + ', 结果AUC=' + str(AUC))
    return (AUC, duration, impurityParm, maxDepthParm, maxBinsParm, model)


(AUC, duration, impurityParm, maxDepthParm, maxBinsParm, model) = trainEvaluateModel(trainData, validationData, 'entropy', 5, 5)

impurityList = ['gini', 'entropy']
maxDepthList = [10]
maxBinsList = [10]
metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)
                for impurity in impurityList
                for maxDepth in maxDepthList
                for maxBins in maxBinsList]



indexList = impurityList
df = pd.DataFrame(metrics, index=indexList, columns=['AUC', 'duration', 'impurity', 'maxDepth', 'maxBins', 'model'])
df

def showChart(df, evalParm, barData, lineData, yMin, yMax):
    # 绘制直方图
    ax = df[barData].plot(kind='bar', title=evalParm, figsize=(10, 6), legend=True, fontsize=12)
    ax.set_xlabel(evalParm, fontsize=12)
    ax.set_ylim([yMin, yMax])
    ax.set_ylabel(barData, fontsize=12)
    # 绘制折线图
    ax2 = ax.twinx()
    ax2.plot(df[lineData].values, linestyle='-', marker='o', linewidth=2.0, color='r')
    plt.show()  # 绘制图形


def evalParameter(trainData, validationData, evalParm, impurityList, maxDepthList, maxBinsList):
    print('======================= 评估模型参数(' + evalParm + ') =======================')
    # 训练评估参数
    metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)
               for impurity in impurityList
               for maxDepth in maxDepthList
               for maxBins in maxBinsList]
    # 设置当前评估的参数
    if evalParm == 'impurity':
        indexList = impurityList[:]
    elif evalParm == 'maxDepth':
        indexList = maxDepthList[:]
    elif evalParm == 'maxBins':
        indexList = maxBinsList[:]
    # 转换为Pandas DataFrame
    df = pd.DataFrame(metrics, index=indexList, columns=['AUC', 'duration', 'impurity', 'maxDepth', 'maxBins', 'model'])
    # 显示图形
    showChart(df, 'impurity', 'AUC', 'duration', 0.5, 0.7)


evalParameter(trainData, validationData, 'impurity',
                  impurityList=['gini', 'entropy'],
                  maxDepthList=[10],
                  maxBinsList=[10])


evalParameter(trainData, validationData, 'maxDepth',
                    impurityList=['gini'],
                    maxDepthList = [3, 5, 10, 15, 20, 25],
                    maxBinsList = [10])

evalParameter(trainData, validationData, 'maxBins',
                  impurityList=['gini'],
                  maxDepthList=[10],
                  maxBinsList=[3, 5, 10, 50, 100, 200])


def evalAllParameter(trainData, validationData, impurityList, maxDepthList, maxBinsList):
    print('======================= 训练评估所有参数，找出最好的参数组合 =======================')
    # for循环训练评估所有参数组合
    metrics = [trainEvaluateModel(trainData, validationData, impurity, maxDepth, maxBins)
               for impurity in impurityList
               for maxDepth in maxDepthList
               for maxBins in maxBinsList]
    # 找出AUC最大的参数组合
    Smetrics = sorted(metrics, key=lambda k: k[0], reverse=True)
    bestParameter = Smetrics[0]
    # 显示调校后最佳参数组合
    print('========== [evalAllParameter] >>>> 调校后最佳参数组合：impurity=' + str(bestParameter[2]) + ', maxDepth=' + str(bestParameter[3]) + ', maxBins=' + str(bestParameter[4]) + '\n' +
          '\t\t==>> 结果AUC=' + str(bestParameter[0]))
    # 返回最佳模型
    return bestParameter[5]

bestModel = evalAllParameter(trainData, validationData,
            ['gini', 'entropy'],
            [3, 5, 10, 15, 20, 25],
            [3, 5, 10, 50, 100, 200])





